{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to make a simple feedforward network to learn the XOR gate behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_1  x_2  y\n",
       "0    0    0  0\n",
       "1    0    1  1\n",
       "2    1    0  1\n",
       "3    1    1  0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "XOR = pd.DataFrame([\n",
    "    [0, 0, 0], \n",
    "    [0, 1, 1], \n",
    "    [1, 0, 1], \n",
    "    [1, 1, 0]], columns=[\"x_1\", \"x_2\", \"y\"])\n",
    "\n",
    "XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_features = 2\n",
    "num_iter = 100000\n",
    "display_step = int(num_iter / 10)\n",
    "learning_rate = 0.01\n",
    "\n",
    "num_input = 2          # units in the input layer 28x28 images\n",
    "num_hidden1 = 2        # units in the first hidden layer\n",
    "num_output = 1         # units in the output, only one output 0 or 1\n",
    "\n",
    "# x, y = XOR.as_matrix(columns=[\"x_1\", \"x_2\"]), XOR.as_matrix(columns=[\"y\"])\n",
    "# y = np.reshape(y, [4,1]) \n",
    "\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], np.float32)  # 4x2, input\n",
    "y = np.array([0, 1, 1, 0], np.float32)                      # 4, correct output, AND operation\n",
    "y = np.reshape(y, [4,1]) \n",
    "\n",
    "# trainum_inputg data and labels\n",
    "X = tf.placeholder('float', [None, num_input])     # training data\n",
    "Y = tf.placeholder('float', [None, num_output])    # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP approximation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layer_perceptron_xor(x, weights, biases):\n",
    "  hidden_layer1 = tf.add(tf.matmul(x, weights['w_h1']), biases['b_h1'])\n",
    "  hidden_layer1 = tf.nn.sigmoid(hidden_layer1)\n",
    "  out_layer = tf.add(tf.matmul(hidden_layer1, weights['w_out']), biases['b_out'])\n",
    " \n",
    "  return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "weights = {\n",
    " 'w_h1' : tf.Variable(tf.random_normal([num_input, num_hidden1])),\n",
    " 'w_out': tf.Variable(tf.random_normal([num_hidden1, num_output]))\n",
    "}\n",
    " \n",
    "biases = {\n",
    " 'b_h1' : tf.Variable(tf.zeros([num_hidden1])),\n",
    " 'b_out': tf.Variable(tf.zeros([num_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_layer_perceptron_xor(X, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  [[0.92657596]\n",
      " [1.0481822 ]\n",
      " [1.271105  ]\n",
      " [1.3435489 ]]\n",
      "loss= 3.40361\n",
      "output:  [[-2.1764343 ]\n",
      " [ 0.51524925]\n",
      " [ 0.8902612 ]\n",
      " [ 0.44862747]]\n",
      "loss= 1.86233\n",
      "output:  [[-2.7589946]\n",
      " [ 2.940815 ]\n",
      " [ 2.9366026]\n",
      " [-2.5233374]]\n",
      "loss= 0.24176\n",
      "output:  [[-3.5402842]\n",
      " [ 3.791689 ]\n",
      " [ 3.7888622]\n",
      " [-3.414403 ]]\n",
      "loss= 0.10564\n",
      "output:  [[-3.9874058]\n",
      " [ 4.259204 ]\n",
      " [ 4.257001 ]\n",
      " [-3.8916216]]\n",
      "loss= 0.06669\n",
      "output:  [[-4.29852  ]\n",
      " [ 4.5809402]\n",
      " [ 4.57909  ]\n",
      " [-4.2174873]]\n",
      "loss= 0.04853\n",
      "output:  [[-4.5368414]\n",
      " [ 4.825783 ]\n",
      " [ 4.8241653]\n",
      " [-4.4647474]]\n",
      "loss= 0.03808\n",
      "output:  [[-4.7297163]\n",
      " [ 5.0233507]\n",
      " [ 5.021901 ]\n",
      " [-4.6639595]]\n",
      "loss= 0.03131\n",
      "output:  [[-4.891535 ]\n",
      " [ 5.1890335]\n",
      " [ 5.187788 ]\n",
      " [-4.830205 ]]\n",
      "loss= 0.02657\n",
      "output:  [[-5.0314074]\n",
      " [ 5.330593 ]\n",
      " [ 5.32938  ]\n",
      " [-4.97371  ]]\n",
      "loss= 0.02307\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- cost function and optimization\n",
    "- sigmoid cross entropy -- single output\n",
    "- softmax cross entropy -- multiple output, normalized\n",
    "'''\n",
    "loss_func = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss_func)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for k in range(num_iter):\n",
    "    tmp_cost, _ = sess.run([loss_func, optimizer], feed_dict={X: x, Y: y})\n",
    "    if k % display_step == 0:\n",
    "        print('output: ', sess.run(model, feed_dict={X:x}))\n",
    "        print('loss= ' + \"{:.5f}\".format(tmp_cost))\n",
    "\n",
    "# separates the input space\n",
    "W = np.squeeze(sess.run(weights['w_h1']))   # 2x2\n",
    "b = np.squeeze(sess.run(biases['b_h1']))    # 2,\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
